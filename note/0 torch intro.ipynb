{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch模块介绍\n",
    "# 主要有为了多维张量tensor而准备的数据结构\n",
    "# 以及针对多维张量运算的各种算子，矩阵乘法、element-wise乘法+比较大小等算子，还有张量的序列化(存储、加载)\n",
    "#\n",
    "# 随机数、各种tensor(zero、ones)的定义、维度操作(加、减一个维度)、\n",
    "# 张量拼接与拆分、求导、数学运算(三角函数、加减乘除、按位与/或/异或、指数、最大最小)\n",
    "# flip、线性代数、相等...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn 模块\n",
    "# 包含了各种构建网络架构的building blocks\n",
    "import torch.nn as nn\n",
    "\n",
    "blocks_all = [\n",
    "    'Containers',\n",
    "    'Convolution layers',\n",
    "    'Pooling layers',\n",
    "    'Padding layers',\n",
    "    'Non-linear Activations(weighted-sum,nonlinearity)',\n",
    "    'Non-linear Activations(other)',\n",
    "    'Normalization layers',\n",
    "    'Recurrent layers',\n",
    "    'Transformer layers',\n",
    "    'Linear layers',\n",
    "    'Droupout layers',\n",
    "    'Sparse layers',\n",
    "    'Distance functions',\n",
    "    'Loss functions',\n",
    "    'Vision layers',\n",
    "    'Shuffle layers',\n",
    "    'DataParallel layers(multi-GPU,distributed)',\n",
    "    'Utilities',\n",
    "    'Quantized functions',\n",
    "    'Lazy Modules Initilization',\n",
    "] \n",
    "# Containers\n",
    "'''nn.Module'''                                  ## Base class.所有的网络组件都是继承自Module类\n",
    "'''nn.Squential'''                               ## 用来构建网络pipeline的容器\n",
    "'''nn.ModuleList'''                              ##   |\n",
    "'''nn.ModuleDict'''                              ##   |\n",
    "'''nn.ParameterList'''                           ##   ↓\n",
    "'''nn.ParameterDict'''                           ## 用List/Dict来组合模型/参数\n",
    "\n",
    "# Convolution layers                                各种卷积层1D,2D,3D及变种\n",
    "# Pooling layers                                    各种池化层1D,2D,3D及变种\n",
    "# Padding layers                                    各种padding层\n",
    "# Non-linear Activations(weighted-sum,nonlinearity) 各种激活函数nn.ReLU等\n",
    "# Non-linear Activations(other)                     nn.Softmax,nn.Softmin及变种\n",
    "# Normalization layers                              各种归一化/标准化操作,nn.BatchNorm及变种\n",
    "# Recurrent layers                                  nn.RNN,nn.LSTM,及几个变种\n",
    "# Transformer layers                                transformer层,主要有5种\n",
    "'''nn.Transformer'''\n",
    "'''nn.TransformerEncoder'''\n",
    "'''nn.TransformerDecoder'''\n",
    "'''nn.TransformerEncodeerlayer'''\n",
    "'''nn.TransformerDecodeerLayer'''\n",
    "\n",
    "# Linear layers                                    全连接层nn.Linear,nn.Identity\n",
    "# Droupout layers                                  Dropout层，随机将输入tensor的部分元素置0\n",
    "# Sparse layers                                    nn.Embedding,nn.EmbeddingBag\n",
    "# Distance functions                               nn.CosineSimilarity(余弦相似度),nn.PairwiseDistance\n",
    "# Loss functions\n",
    "'''nn.MSELoss'''\n",
    "'''nn.CrossEntropyLoss'''                       ## 损失函数层...\n",
    "\n",
    "'''以及许多的工具函数'''\n",
    "# Vision layers\n",
    "# Shuffle layers\n",
    "# DataParallel layers(multi-GPU,distributed)\n",
    "# Utilities\n",
    "# Quantized functions\n",
    "# Lazy Modules Initilization\n",
    "# \n",
    "# Example.\n",
    "import torch\n",
    "\n",
    "input = torch.randn(32,1,5,5)\n",
    "m = nn.Flatten(start_dim=0,end_dim=2) # 将维度[0,1,2]组合\n",
    "output = m(input)                     # [160,5]\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'torch.nn.functional模块'\n",
    "# 提供了nn模块的同名函数\n",
    "\n",
    "'torch.utils模块'\n",
    "import torch.utils.data.DataLoader as dataloader\n",
    "'''\n",
    "DataLoader(\n",
    "dataset, \n",
    "batch_size=1, \n",
    "shuffle=False, \n",
    "sampler=None,\n",
    "batch_sampler=None, \n",
    "num_workers=0, \n",
    "collate_fn=None,\n",
    "pin_memory=False, \n",
    "drop_last=False, \n",
    "timeout=0,\n",
    "worker_init_fn=None, \n",
    "*, \n",
    "prefetch_factor=2,\n",
    "persistent_workers=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c12c839adeec326d421be117b103b29d3b0068db2c28a64ae1df63f05821871"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
